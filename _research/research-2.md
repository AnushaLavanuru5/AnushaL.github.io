---
title: "PolXR"
excerpt: "Dec 2020 Short description of portfolio item number 1<br/><img src='/images/500x300.png'>"
collection: research
---
Overview
---
Developed a machine learning-based system to recognize hand gestures for enhancing human-computer interaction. The project explored feature extraction techniques and leveraged image processing and neural networks to classify static hand gestures effectively.

Key features
---
- Implemented Histogram of Oriented Gradients (HOG) and Fibonacci Weighted Neighborhood Patterns (FWNP) for robust feature extraction.
- Utilized a neural network architecture to classify gestures with high accuracy.
- Developed an efficient system capable of recognizing gestures under varying conditions such as changes in lighting, background, and scale.

Applications
---
- Touchless control of electronic devices and gadgets.
- Applications in home automation, gaming, defense, and sign language translation.

Tech Stack
---
- **Programming Languages**: Python
- **Libraries**: OpenCV, TensorFlow, Keras
- **Dataset**: NUS Hand Posture Dataset
- **Tools**: Jupyter Notebook, Anaconda

Project highlights
---
- Pre-processed images using segmentation, noise reduction, and edge detection techniques to isolate hand gestures.
- Designed a pipeline to capture gestures via webcam and classify them in real-time.
- Achieved high recognition accuracy by combining boundary-based and region-based feature extraction methods.

Future Scope
---
- Enhance robustness with more gestures and varied backgrounds using advanced machine learning models.
- Integrate depth-sensing cameras for better accuracy in complex environments.
- Explore applications in gesture-based TV controls, gaming, and AR/VR interfaces.

